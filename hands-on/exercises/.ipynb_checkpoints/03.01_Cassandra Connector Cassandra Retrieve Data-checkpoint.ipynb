{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataStax Academy](https://s3.amazonaws.com/datastaxtraining/vq8Jr36Gk48v/datastax-academy.svg \"DataStax Academy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 03.01 - Cassandra Connector: Cassandra Retrieve Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will have you practice using the Spark Cassandra API, which you'll be using to implement a CQL query to retrieve data in Spark.\n",
    "\n",
    "The data comes from a Cassandra table, `videos_by_year_title`, with the following definition:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE killr_video.videos_by_year_title (\n",
    "    added_year INT,\n",
    "    title TEXT,\n",
    "    video_id TIMEUUID,\n",
    "    added_date TIMESTAMP,\n",
    "    avg_rating FLOAT,\n",
    "    description TEXT,\n",
    "    user_id UUID,\n",
    "    PRIMARY KEY (added_year, title, video_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write a Spark query to retrieve movies in the year 2015 where the movie title starts with the letter `T` or greater. Print the results taking only the first five records. Be sure to use the Spark Cassandra API rather than the Spark functions themselves so that Cassandra does as much of the processing as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Rewrite your query to use Spark API instead of the Spark Cassandra API functions. Remember that this way is less optimal because it causes Spark to load and process all the data from Cassandra itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
